{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wyZiVR9GBWj3"
      },
      "outputs": [],
      "source": [
        "!pip install langchain -q\n",
        "!pip install openai -q\n",
        "!pip install chromaDB -q\n",
        "!pip install unstructured -q\n",
        "!pip install tiktoken\n",
        "!pip install streamlit\n",
        "!pip install pyngrok\n",
        "!pip install pytube -q\n",
        "!apt-get install -y tesseract-ocr\n",
        "!apt-get install -y poppler-utils"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U unstructured"
      ],
      "metadata": {
        "id": "YRsDyrm6Vm7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install \"unstructured[pdf]\""
      ],
      "metadata": {
        "id": "9PJzzg9dtSdz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"unstructured[pdf]\" -q"
      ],
      "metadata": {
        "id": "EPA-S6GhEvCp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.document_loaders import UnstructuredFileLoader\n",
        "from langchain.document_loaders.image import UnstructuredImageLoader\n",
        "from langchain.document_loaders import ImageCaptionLoader\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.document_loaders import UnstructuredFileLoader\n",
        "import os\n",
        "import pytube\n",
        "import openai\n",
        "\n",
        "# Chat UI title\n",
        "st.header(\"Upload your own file and ask questions like ChatGPT\")\n",
        "st.subheader('File types supported: PDF')\n",
        "\n",
        "# File uploader in the sidebar on the left\n",
        "with st.sidebar:\n",
        "    # Input for OpenAI API Key\n",
        "    openai_api_key = st.text_input(\"OpenAI API Key\", type=\"password\")\n",
        "\n",
        "    # Check if OpenAI API Key is provided\n",
        "    if not openai_api_key:\n",
        "        st.info(\"Please add your OpenAI API key to continue.\")\n",
        "        st.stop()\n",
        "\n",
        "    # Set OPENAI_API_KEY as an environment variable\n",
        "    os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "\n",
        "# Initialize ChatOpenAI model\n",
        "llm = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo-0125\", streaming=True)\n",
        "\n",
        "# Load version history from the text file\n",
        "def load_version_history():\n",
        "    with open(\"version_history.txt\", \"r\") as file:\n",
        "        return file.read()\n",
        "\n",
        "# Sidebar section for uploading files and providing a YouTube URL\n",
        "with st.sidebar:\n",
        "    uploaded_files = st.file_uploader(\"Please upload your files\", accept_multiple_files=True, type=None)\n",
        "    #youtube_url = st.text_input(\"YouTube URL\")\n",
        "\n",
        "    # Create an expander for the version history in the sidebar\n",
        "    with st.sidebar.expander(\"**Version History**\", expanded=False):\n",
        "      st.write(load_version_history())\n",
        "\n",
        "    #st.info(\"Please refresh the browser if you decide to upload more files to reset the session\", icon=\"ðŸš¨\")\n",
        "\n",
        "# Check if files are uploaded or YouTube URL is provided\n",
        "if uploaded_files:\n",
        "    # Print the number of files uploaded or YouTube URL provided to the console\n",
        "    st.write(\"file uploaded successfully\")\n",
        "\n",
        "    # Load the data and perform preprocessing only if it hasn't been loaded before\n",
        "    if \"processed_data\" not in st.session_state:\n",
        "        # Load the data from uploaded files\n",
        "        documents = []\n",
        "\n",
        "        if uploaded_files:\n",
        "            for uploaded_file in uploaded_files:\n",
        "                # Get the full file path of the uploaded file\n",
        "                file_path = os.path.join(os.getcwd(), uploaded_file.name)\n",
        "\n",
        "                # Save the uploaded file to disk\n",
        "                with open(file_path, \"wb\") as f:\n",
        "                    f.write(uploaded_file.getvalue())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                if file_path.endswith(\".pdf\"):\n",
        "                    # Use UnstructuredFileLoader to load the PDF\n",
        "                    loader = UnstructuredFileLoader(file_path)\n",
        "                    loaded_documents = loader.load()\n",
        "\n",
        "                    # Extend the main documents list with the loaded documents\n",
        "                    documents.extend(loaded_documents)\n",
        "\n",
        "\n",
        "        # Chunk the data, create embeddings, and save in vectorstore\n",
        "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=150)\n",
        "        document_chunks = text_splitter.split_documents(documents)\n",
        "\n",
        "\n",
        "        embeddings = OpenAIEmbeddings()\n",
        "        vectorstore = Chroma.from_documents(document_chunks, embeddings)\n",
        "\n",
        "        # Store the processed data in session state for reuse\n",
        "        st.session_state.processed_data = {\n",
        "            \"document_chunks\": document_chunks,\n",
        "            \"vectorstore\": vectorstore,\n",
        "        }\n",
        "\n",
        "    else:\n",
        "        # If the processed data is already available, retrieve it from session state\n",
        "        document_chunks = st.session_state.processed_data[\"document_chunks\"]\n",
        "        vectorstore = st.session_state.processed_data[\"vectorstore\"]\n",
        "\n",
        "    # Initialize Langchain's QA Chain with the vectorstore\n",
        "    qa = ConversationalRetrievalChain.from_llm(llm, vectorstore.as_retriever())\n",
        "\n",
        "    # Initialize chat history\n",
        "    if \"messages\" not in st.session_state:\n",
        "        st.session_state.messages = []\n",
        "\n",
        "    # Display chat messages from history on app rerun\n",
        "    for message in st.session_state.messages:\n",
        "        with st.chat_message(message[\"role\"]):\n",
        "            st.markdown(message[\"content\"])\n",
        "\n",
        "    # Accept user input\n",
        "    if prompt := st.chat_input(\"Ask your questions?\"):\n",
        "        st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "        with st.chat_message(\"user\"):\n",
        "            st.markdown(prompt)\n",
        "\n",
        "        # Query the assistant using the latest chat history\n",
        "        history = [\n",
        "            f\"{message['role']}: {message['content']}\"\n",
        "            for message in st.session_state.messages\n",
        "        ]\n",
        "\n",
        "        # Convert the string list to list of tuples\n",
        "        chat_history = [(message.split(\": \")[0], message.split(\": \")[1]) for message in history]\n",
        "\n",
        "\n",
        "        result = qa({\n",
        "            \"question\": prompt,\n",
        "            \"chat_history\": chat_history\n",
        "        })\n",
        "\n",
        "        # Display assistant response in chat message container\n",
        "        with st.chat_message(\"assistant\"):\n",
        "            message_placeholder = st.empty()\n",
        "            full_response = result[\"answer\"]\n",
        "            message_placeholder.markdown(full_response + \"|\")\n",
        "        message_placeholder.markdown(full_response)\n",
        "        print(full_response)\n",
        "        st.session_state.messages.append({\"role\": \"assistant\", \"content\": full_response})\n",
        "\n",
        "else:\n",
        "    st.write(\"Please upload your files\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGTdYWkmBuVY",
        "outputId": "23fcbecb-d6f6-4eea-c01b-1c67cdd7e9db"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import time\n",
        "\n",
        "#Set auth token\n",
        "ngrok.set_auth_token(\"2c54S0BCzBB0ZiGw5FSS82ulUNb_7wsNuyyPb22woziTCnnXn\")\n",
        "\n",
        "# Wait for the Flask app to start\n",
        "#time.sleep(2)\n",
        "\n",
        "!nohup streamlit run app.py --server.port 5011 &\n",
        "# Start ngrok tunnel\n",
        "ngrok_tunnel = ngrok.connect(addr='5011', proto='http', bind_tls=True)\n",
        "\n",
        "# Print the URL\n",
        "print(' * Tunnel URL:', ngrok_tunnel.public_url)\n",
        "\n",
        "# Keep the Colab session alive\n",
        "while True:\n",
        "    time.sleep(120)  # Keep the session alive for 120sec"
      ],
      "metadata": {
        "id": "2BRmYXo4B5NQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}