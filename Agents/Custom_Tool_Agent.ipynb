{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOREqad9kScc"
      },
      "outputs": [],
      "source": [
        "!pip install langchain-q\n",
        "!pip install openai\n",
        "%pip install --upgrade --quiet  langchain langchain-community langchain-openai\n",
        "!pip install faiss-gpu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = 'OPENAI API KEY'\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = 'LANGCHAIN KEY'\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"Agents\""
      ],
      "metadata": {
        "id": "5GAqeSg4kvfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the language model\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI()"
      ],
      "metadata": {
        "id": "aWmSw4kjk1-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import things that are needed generically\n",
        "from langchain.pydantic_v1 import BaseModel, Field\n",
        "from langchain.tools import BaseTool, StructuredTool, tool"
      ],
      "metadata": {
        "id": "CBguN7S7k9ps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Defining a tool using @tool decorator"
      ],
      "metadata": {
        "id": "yJR-w_ChnXVa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def searchLangchain(query:str)->str:\n",
        "  \"\"\"Look up things online\"\"\"\n",
        "  return \"Langchain\""
      ],
      "metadata": {
        "id": "L7JSyHPdl2xP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(searchLangchain.name)\n",
        "print(searchLangchain.description)\n",
        "print(searchLangchain.args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4HlERsomF9v",
        "outputId": "799f1cb1-bdb2-4e60-c1a2-7bf20a3e84c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "searchLangchain\n",
            "Look up things online\n",
            "{'query': {'title': 'Query', 'type': 'string'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def multiply(a:int,b:int)->int:\n",
        "  \"\"\"Multiply two numbers\"\"\"\n",
        "  return a*b\n"
      ],
      "metadata": {
        "id": "kvHrm3edmvar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(multiply.description)\n",
        "print(multiply.args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-0NMzh2m9tq",
        "outputId": "35cb36c8-79ab-47ef-edc7-0bacc730a546"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multiply two numbers\n",
            "{'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def get_word_length(word:str)->int:\n",
        "  \"\"\"Get word length\"\"\"\n",
        "  return len(word)"
      ],
      "metadata": {
        "id": "iTkzwYBVnavP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_word_length.invoke(\"Excellent\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yf4lScbunlZw",
        "outputId": "e0ab856d-2634-4430-e1b8-3dafa1093c00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tools=[get_word_length]"
      ],
      "metadata": {
        "id": "F38RFAp1nyC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Create Prompt\n",
        "Now let us create the prompt. Because OpenAI Function Calling is finetuned for tool usage, we hardly need any instructions on how to reason, or how to output format. We will just have two input variables: input and agent_scratchpad. input should be a string containing the user objective. agent_scratchpad should be a sequence of messages that contains the previous agent tool invocations and the corresponding tool outputs."
      ],
      "metadata": {
        "id": "VDuACVLYn6as"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\",\"You are a powerful assistant, but dont know the status of previous tool calls\"),\n",
        "    (\"user\",\"{input}\"),\n",
        "    MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
        "\n",
        "])"
      ],
      "metadata": {
        "id": "eNOsiHn0n9Z3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Bind Tools to LLM\n",
        "How does the agent know what tools it can use?\n",
        "\n",
        "In this case we're relying on OpenAI tool calling LLMs, which take tools as a separate argument and have been specifically trained to know when to invoke those tools.\n",
        "\n",
        "To pass in our tools to the agent, we just need to format them to the OpenAI tool format and pass them to our model. (By bind-ing the functions, we're making sure that they're passed in each time the model is invoked.)"
      ],
      "metadata": {
        "id": "U8Po0-0cpsT7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm_with_tools = llm.bind_tools(tools)"
      ],
      "metadata": {
        "id": "TYQ6DIjOpDso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Create the Agent\n",
        "Putting those pieces together, we can now create the agent. We will import two last utility functions: a component for formatting intermediate steps (agent action, tool output pairs) to input messages that can be sent to the model, and a component for converting the output message into an agent action/agent finish."
      ],
      "metadata": {
        "id": "mx3673hjqqMo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents.format_scratchpad.openai_tools import (\n",
        "    format_to_openai_tool_messages,\n",
        ")\n",
        "from langchain.agents.output_parsers.openai_tools import OpenAIToolsAgentOutputParser\n",
        "\n",
        "agent = (\n",
        "    {\n",
        "        \"input\": lambda x: x[\"input\"],\n",
        "        \"agent_scratchpad\": lambda x: format_to_openai_tool_messages(\n",
        "            x[\"intermediate_steps\"]\n",
        "        ),\n",
        "    }\n",
        "    | prompt\n",
        "    | llm_with_tools\n",
        "    | OpenAIToolsAgentOutputParser()\n",
        ")"
      ],
      "metadata": {
        "id": "x0rYXjHaqsL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import AgentExecutor\n",
        "\n",
        "agent_executor=AgentExecutor(agent=agent,tools=tools,verbose=True)"
      ],
      "metadata": {
        "id": "cc19An4nq8oe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor.invoke({\"input\":\"How many letters in the work Fantastic\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkpZmrt4rKc3",
        "outputId": "a0b0aeea-e329-46d2-d2ee-ac077cd3a618"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `get_word_length` with `{'word': 'Fantastic'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m9\u001b[0m\u001b[32;1m\u001b[1;3mThe word \"Fantastic\" has 9 letters.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'How many letters in the work Fantastic',\n",
              " 'output': 'The word \"Fantastic\" has 9 letters.'}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list[agent_executor.stream({\"input\":\"How many letters in the work Fantastic\"})]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KqDmIxDrZ59",
        "outputId": "ad45cb09-37e5-40d5-d358-3b8b3019e0f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list[<generator object AgentExecutor.stream at 0x7a465bbef450>]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Adding Memory\n",
        "This is great - we have an agent! However, this agent is stateless - it doesn't remember anything about previous interactions. This means you can't ask follow up questions easily. Let's fix that by adding in memory.\n",
        "\n",
        "In order to do this, we need to do two things:\n",
        "\n",
        "Add a place for memory variables to go in the prompt\n",
        "Keep track of the chat history\n",
        "First, let's add a place for memory in the prompt. We do this by adding a placeholder for messages with the key \"chat_history\". Notice that we put this ABOVE the new user input (to follow the conversation flow)."
      ],
      "metadata": {
        "id": "zbvbuwYA5iL8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\",\"You are a powerful assistant, but bad at calculating length of words\"),\n",
        "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "    (\"user\",\"{input}\"),\n",
        "    MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
        "])"
      ],
      "metadata": {
        "id": "sLZ0RfAg5jUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage,AIMessage\n",
        "chat_history=[]\n",
        "\n",
        "agent = (\n",
        "    {\n",
        "        \"input\": lambda x: x[\"input\"],\n",
        "        \"agent_scratchpad\": lambda x: format_to_openai_tool_messages(\n",
        "            x[\"intermediate_steps\"]\n",
        "        ),\n",
        "        \"chat_history\": lambda x: x[\"chat_history\"],\n",
        "    }\n",
        "    | prompt\n",
        "    | llm_with_tools\n",
        "    | OpenAIToolsAgentOutputParser()\n",
        ")\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
      ],
      "metadata": {
        "id": "11qs-Ye06dPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input1 = \"how many letters in the word educa?\"\n",
        "result = agent_executor.invoke({\"input\": input1, \"chat_history\": chat_history})\n",
        "chat_history.extend(\n",
        "    [\n",
        "        HumanMessage(content=input1),\n",
        "        AIMessage(content=result[\"output\"]),\n",
        "    ]\n",
        ")\n",
        "agent_executor.invoke({\"input\": \"is that a real english word?\", \"chat_history\": chat_history})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiIO1nYA7bis",
        "outputId": "2c25f161-4238-4317-902d-25910568ffbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `get_word_length` with `{'word': 'educa'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m5\u001b[0m\u001b[32;1m\u001b[1;3mThe word \"educa\" has 5 letters.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `get_word_length` with `{'word': 'educa'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m5\u001b[0m\u001b[32;1m\u001b[1;3mThe word \"educa\" has 5 letters. It is not a common English word.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'is that a real english word?',\n",
              " 'chat_history': [HumanMessage(content='how many letters in the word educa?'),\n",
              "  AIMessage(content='The word \"educa\" has 5 letters.'),\n",
              "  HumanMessage(content='how many letters in the word educa?'),\n",
              "  AIMessage(content='The word \"educa\" has 5 letters.')],\n",
              " 'output': 'The word \"educa\" has 5 letters. It is not a common English word.'}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    }
  ]
}