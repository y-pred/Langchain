{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install chromadb -q"
      ],
      "metadata": {
        "collapsed": true,
        "id": "lKunJIXggJV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain -q\n",
        "!pip install openai -q"
      ],
      "metadata": {
        "id": "c324cot-gfRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade --quiet  langchain langchain-community langchain-openai"
      ],
      "metadata": {
        "id": "RTOSEanahK03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a13f83a-a54d-4e83-ad0c-a850f4e98405"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = 'OPENAI_API_KEY'\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = 'LANGCHAIN_KEY'"
      ],
      "metadata": {
        "id": "AdOaWiDsgzW1"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Example Selector\n",
        "If you have a large number of examples, you may need to select which ones to include in the prompt. The Example Selector is the class responsible for doing so."
      ],
      "metadata": {
        "id": "c2KiYgC9f0aM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Select by length"
      ],
      "metadata": {
        "id": "N5Mkon0tIbuD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.example_selectors import LengthBasedExampleSelector\n",
        "from langchain_core.prompts import FewShotPromptTemplate, PromptTemplate\n"
      ],
      "metadata": {
        "id": "9zcCa1yiIem5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "examples = [\n",
        "    {\"input\":\"happy\",\"output\":\"sad\"},\n",
        "    {\"input\":\"long\",\"output\":\"short\"},\n",
        "    {\"input\":\"day\",\"output\":\"night\"},\n",
        "    {\"input\":\"boy\",\"output\":\"girl\"},\n",
        "    {\"input\":\"sunny\",\"output\":\"gloomy\"},\n",
        "\n",
        "]\n",
        "\n",
        "example_prompt = PromptTemplate.from_template(\"Input: {input}\\nOutput: {output}\")\n",
        "\n",
        "example_selector = LengthBasedExampleSelector(\n",
        "    examples = examples,\n",
        "    example_prompt=example_prompt,\n",
        "    max_length=25\n",
        ")\n",
        "\n",
        "dynamic_prompt = FewShotPromptTemplate(\n",
        "    example_selector=example_selector,\n",
        "    example_prompt=example_prompt,\n",
        "    prefix=\"Give the antonym of every input\",\n",
        "    suffix=\"Input: {adjective}\\nOutput:\",\n",
        "    input_variables=[\"adjective\"]\n",
        ")"
      ],
      "metadata": {
        "id": "u6dCDY1GIrYY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dynamic_prompt.format(adjective = \"Beautiful\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYHa2dskKZbL",
        "outputId": "4cf48e11-1436-4d39-ea4e-93de381115a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Give the antonym of every input\n",
            "\n",
            "Input: happy\n",
            "Output: sad\n",
            "\n",
            "Input: long\n",
            "Output: short\n",
            "\n",
            "Input: day\n",
            "Output: night\n",
            "\n",
            "Input: boy\n",
            "Output: girl\n",
            "\n",
            "Input: sunny\n",
            "Output: gloomy\n",
            "\n",
            "Input: Beautiful\n",
            "Output:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# An example with long input, so it selects only one example.\n",
        "long_string = \"big and huge and massive and large and gigantic and tall and much much much much much bigger than everything else\"\n",
        "print(dynamic_prompt.format(adjective=long_string))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gl0DCH9TKnvw",
        "outputId": "7e40c9dc-40b6-49df-8c9f-9ee54146b59c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Give the antonym of every input\n",
            "\n",
            "Input: happy\n",
            "Output: sad\n",
            "\n",
            "Input: big and huge and massive and large and gigantic and tall and much much much much much bigger than everything else\n",
            "Output:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Selection by Similarity\n",
        "\n",
        "\n",
        "*   This object selects examples based on similarity to the inputs. It does this by finding the examples with the embeddings that have the greatest cosine similarity with the inputs\n"
      ],
      "metadata": {
        "id": "zIXHaiDHvVpN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_core.example_selectors import SemanticSimilarityExampleSelector\n",
        "from langchain_core.prompts import FewShotPromptTemplate, PromptTemplate\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "example_prompt = PromptTemplate(\n",
        "    input_variables=[\"input\", \"output\"],\n",
        "    template=\"Input: {input}\\nOutput: {output}\",\n",
        ")\n",
        "\n",
        "# Examples of a pretend task of creating antonyms.\n",
        "examples = [\n",
        "    {\"input\": \"happy\", \"output\": \"sad\"},\n",
        "    {\"input\": \"tall\", \"output\": \"short\"},\n",
        "    {\"input\": \"energetic\", \"output\": \"lethargic\"},\n",
        "    {\"input\": \"sunny\", \"output\": \"gloomy\"},\n",
        "    {\"input\": \"windy\", \"output\": \"calm\"},\n",
        "]"
      ],
      "metadata": {
        "id": "0675OvzvfvNO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
        "    # The list of examples available to select from.\n",
        "    examples,\n",
        "    # The embedding class used to produce embeddings which are used to measure semantic similarity.\n",
        "    OpenAIEmbeddings(),\n",
        "    # The VectorStore class that is used to store the embeddings and do a similarity search over.\n",
        "    Chroma,\n",
        "    # The number of examples to produce.\n",
        "    k=1,\n",
        ")\n",
        "similar_prompt = FewShotPromptTemplate(\n",
        "    # We provide an ExampleSelector instead of examples.\n",
        "    example_selector=example_selector,\n",
        "    example_prompt=example_prompt,\n",
        "    prefix=\"Give the antonym of every input\",\n",
        "    suffix=\"Input: {adjective}\\nOutput:\",\n",
        "    input_variables=[\"adjective\"],\n",
        ")"
      ],
      "metadata": {
        "id": "pvERu7aYhTmP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input is a feeling, so should select the happy/sad example\n",
        "print(similar_prompt.format(adjective=\"worried\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auZPg7SuhanU",
        "outputId": "3aaa21c3-abd9-461e-91d5-734d62e08d3f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Give the antonym of every input\n",
            "\n",
            "Input: happy\n",
            "Output: sad\n",
            "\n",
            "Input: worried\n",
            "Output:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Input is a measurement, so should select the tall/short example\n",
        "print(similar_prompt.format(adjective=\"large\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYA0RLTUhfz2",
        "outputId": "d9650aae-1a79-498e-fb2a-8e171816bcdd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Give the antonym of every input\n",
            "\n",
            "Input: tall\n",
            "Output: short\n",
            "\n",
            "Input: large\n",
            "Output:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XV-EbhpZddwU"
      },
      "outputs": [],
      "source": []
    }
  ]
}