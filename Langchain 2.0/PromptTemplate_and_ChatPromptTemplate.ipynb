{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUoyOyd6dYwu"
      },
      "outputs": [],
      "source": [
        "!pip install langchain\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade --quiet  langchain langchain-community langchain-openai"
      ],
      "metadata": {
        "id": "dzvFz51hgs02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63a7f220-3f22-4d0e-d52b-8bb7223769fb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = 'OPENAI_API_KEY'\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = 'LANGCHAIN_KEY'"
      ],
      "metadata": {
        "id": "_c2Sz8ZhfqAg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "Lk-PJ3XJnZ6F"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature=0.2)\n",
        "llm(\"Give me five destinations to visit in India\")"
      ],
      "metadata": {
        "id": "baLtjgtXnfNp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "e4790160-9102-41cf-f298-e022f6fe1e9f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n\\n1. The Taj Mahal in Agra: This iconic monument is a must-visit for anyone traveling to India. Built in the 17th century by Mughal Emperor Shah Jahan as a mausoleum for his beloved wife, the Taj Mahal is a stunning example of Mughal architecture and is considered one of the most beautiful buildings in the world.\\n\\n2. The Golden Temple in Amritsar: Located in the city of Amritsar in Punjab, the Golden Temple is the holiest site for Sikhs and is a major pilgrimage destination. The temple is known for its stunning golden architecture and its peaceful atmosphere, making it a must-visit for spiritual seekers.\\n\\n3. The backwaters of Kerala: The backwaters of Kerala are a network of interconnected canals, lakes, and lagoons that run parallel to the Arabian Sea. A houseboat ride through the backwaters is a popular tourist activity, offering a unique and tranquil experience of Kerala's natural beauty.\\n\\n4. The beaches of Goa: Goa is known for its beautiful beaches, vibrant nightlife, and Portuguese-influenced architecture. It is a popular destination for both domestic and international tourists, offering a mix of relaxation, adventure, and cultural experiences.\\n\\n5. The Pink City of\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "parser = StrOutputParser()"
      ],
      "metadata": {
        "id": "oUpmy_BI0u_Q"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parser.invoke(llm(\"Give me five destinations to visit in India\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "7kFFffEFnvZO",
        "outputId": "74aea8ad-dfa9-47fc-e3bd-44f9ff1fde1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n1. The Taj Mahal in Agra, Uttar Pradesh - One of the most iconic and beautiful monuments in the world, the Taj Mahal is a must-visit destination in India. Built by Mughal Emperor Shah Jahan in memory of his beloved wife, it is a symbol of love and a UNESCO World Heritage Site.\\n\\n2. The Golden Temple in Amritsar, Punjab - The holiest shrine of Sikhism, the Golden Temple is a stunning architectural marvel with its golden dome and serene surroundings. It is a place of spiritual significance and also offers delicious langar (free community meal) to all visitors.\\n\\n3. The backwaters of Kerala - A network of interconnected canals, lakes, and lagoons, the backwaters of Kerala are a unique and picturesque destination. You can take a houseboat ride and experience the tranquil beauty of the backwaters, surrounded by lush greenery and coconut trees.\\n\\n4. The beaches of Goa - Known for its vibrant nightlife, Goa also has some of the most beautiful beaches in India. From the popular Baga and Calangute beaches to the more secluded ones like Agonda and Palolem, there is something for everyone in Goa.\\n\\n5. The hill stations of Himachal Pradesh - With its snow-c'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Prompts**"
      ],
      "metadata": {
        "id": "DSNe3xRQriF9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "#Instantiate using initializer\n",
        "prompt2 = PromptTemplate(\n",
        "    input_variables=[\"age\"],\n",
        "    template = \"My age is {age}\"\n",
        ")\n",
        "prompt2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FllL3FBWsisk",
        "outputId": "80897d2e-dcd1-4642-9ac9-f5ea7713259a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['age'], template='My age is {age}')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "#Instantiate Prompt using from_template// recommended\n",
        "prompt = PromptTemplate.from_template(\"Good Morning {name}\")\n",
        "prompt.format(name=\"Ashish\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "NM4bgTifr0-F",
        "outputId": "685b58ea-8f46-4ace-980c-21977ffbc34b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Good Morning Ashish'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt2 = PromptTemplate.from_template(\"{name} is {verb} in the park\")\n",
        "prompt2.format(name=\"Ram\", verb='playing')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Ju0gq63Ut8Dx",
        "outputId": "f24a9e87-b235-43d5-8efc-cd3bf88294fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Ram is playing in the park'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "String Prompt Composition"
      ],
      "metadata": {
        "id": "YGkezVe8u3Xx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt3 = (\n",
        "    PromptTemplate.from_template(\"Tell me a joke about {topic}\")\n",
        "    +\",make it funny\"\n",
        "    +\"\\n\\n and in {language}\"\n",
        ")\n",
        "prompt3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asWtMt2Zt4h7",
        "outputId": "0b695724-591f-4b28-b338-0a823b56c29f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['language', 'topic'], template='Tell me a joke about {topic},make it funny\\n\\n and in {language}')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt3.format(topic='Cricket',language='Hindi')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "IEtsYD1NvYJb",
        "outputId": "6ec2a53c-689f-4edc-bceb-60dddff33cf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tell me a joke about Cricket,make it funny\\n\\n and in Hindi'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm(prompt3.format(topic='Cricket',language='Hindi'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "oqBDyZtWrjvH",
        "outputId": "9e07831c-8172-4ad4-fb5f-bc4df0edb1d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nWhy did the cricket go to the doctor?\\n\\nBecause he was feeling a little \"bowled\" over! \\n\\nHindi: क्रिकेट डॉक्टर के पास क्यों गया?\\n\\nक्योंकि उसे थोड़ा सा \"बोल्ड\" लग रहा था!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt4 = (\n",
        "    PromptTemplate.from_template(\"Can we discuss about {topic}.\")\n",
        "    +\"Please describe it in {number} words.\"\n",
        "    +\"Also have a {adjective} tone to it\"\n",
        ")\n",
        "prompt4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDAwWbAnvy0L",
        "outputId": "9ecd2a00-75bd-47c1-fe9a-452a2c3fa1db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['adjective', 'number', 'topic'], template='Can we discuss about {topic}.Please describe it in {number} words.Also have a {adjective} tone to it')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt4.format(topic=\"LLM\",number=\"150\",adjective=\"Rude\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "o9sRhcz6wq2k",
        "outputId": "6711adcf-d049-4f38-8432-098055d4b162"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Can we discuss about LLM.Please describe it in 150 words.Also have a Rude tone to it'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm(prompt4.format(topic=\"LLM\",number=\"150\",adjective=\"Rude\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "BdAwbSZSw5Qd",
        "outputId": "8af03f84-4b0c-46a8-8d6c-44a0924b0cf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n\\nLLM, or Master of Laws, is a postgraduate degree in law that is typically pursued by individuals who have already completed their undergraduate law degree. It is a highly specialized program that allows students to focus on a specific area of law, such as international law, corporate law, or intellectual property law.\\n\\nNow, let's get one thing straight - LLM is not for the faint of heart. It is a rigorous and demanding program that requires a high level of dedication and commitment. So if you're not willing to put in the hard work, then don't even bother applying.\\n\\nAnd don't think that just because you have a law degree, you'll breeze through LLM. This is a whole new level of legal education, and you'll be competing with some of the best and brightest minds in the field. So if you're not up for the challenge, then save yourself the embarrassment and don't even bother.\\n\\nBut if you're ready to push yourself to the limit and truly become an expert in your chosen area of law, then LLM might just be the right path for you. Just be prepared for long hours of studying, intense research, and a whole lot of stress. But hey, no one said becoming a legal master would be easy. So if\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**ChatPromptTemplate**"
      ],
      "metadata": {
        "id": "JGqD4qHNxOxU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "model = ChatOpenAI(model=\"gpt-3.5-turbo\")"
      ],
      "metadata": {
        "id": "MuDSco1l2Hq3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Direct Way"
      ],
      "metadata": {
        "id": "sWW6XIdSBkHL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "chat1 = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\",\"You are a chatbot named {name} and you are funny\"),\n",
        "        (\"human\",\"Hi, How are you doing\"),\n",
        "        (\"ai\",\"Hey man! how are you doing!\"),\n",
        "        (\"human\",\"{user_input}\")\n",
        "    ]\n",
        ")\n",
        "chat1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J45Otr8CxWej",
        "outputId": "267105e0-adfa-4ccd-bc99-fcb1b69f479b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['name', 'user_input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['name'], template='You are a chatbot named {name} and you are funny')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='Hi, How are you doing')), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='Hey man! how are you doing!')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['user_input'], template='{user_input}'))])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "message1 = chat1.format_messages(name=\"Andy\",user_input=\"Can you tell me a trignometry formula?\")\n",
        "message1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgfQR3gj1d2x",
        "outputId": "2ba1d336-e191-47e8-811f-0e4148c981e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SystemMessage(content='You are a chatbot named Andy and you are funny'),\n",
              " HumanMessage(content='Hi, How are you doing'),\n",
              " AIMessage(content='Hey man! how are you doing!'),\n",
              " HumanMessage(content='Can you tell me a trignometry formula?')]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.invoke(message1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwvKtl1410EC",
        "outputId": "c9df7f9c-61a0-4763-9d43-dd9b0af3f55d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Sure! Here\\'s a trigonometry formula for you: \"Some Old Horses Can Always Hear Their Owner Approach.\" It\\'s a mnemonic to remember the trigonometric ratios: Sine = Opposite/Hypotenuse, Cosine = Adjacent/Hypotenuse, Tangent = Opposite/Adjacent.', response_metadata={'token_usage': {'completion_tokens': 64, 'prompt_tokens': 54, 'total_tokens': 118}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-cfccf3ad-a293-4d2b-a0e2-f2d37819f819-0', usage_metadata={'input_tokens': 54, 'output_tokens': 64, 'total_tokens': 118})"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parser.invoke(model.invoke(message1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "r8Oky1Ir2qGW",
        "outputId": "f59926a9-7935-4b3c-a799-39b292b791a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Sure! Here\\'s a trigonometry formula for you: \"Some Old Horses Can Always Hear Their Owner Approach.\" That\\'s a mnemonic to remember the trigonometric functions sine, cosine, tangent, cosecant, secant, and cotangent.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " In addition to using the 2-tuple representation of (type, content) used above, you could pass in an instance of MessagePromptTemplate or BaseMessage\n",
        "\n",
        " In this example we are using SystemMessage and HumanMessage, because we want the message to be printed as it is"
      ],
      "metadata": {
        "id": "tMrQk-q57ASf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
        "message2 = [\n",
        "    SystemMessage(content=\"Translate the following sentence from english to Hindi\"),\n",
        "    HumanMessage(content=\"Hi, I need some help with translation\"),\n",
        "    AIMessage(content=\"Yes please, tell me\")\n",
        "]\n",
        "message2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9aA7imM7ITa",
        "outputId": "4a703d8d-fae4-4219-adc2-0e8c6d841e54"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SystemMessage(content='Translate the following sentence from english to Hindi'),\n",
              " HumanMessage(content='Hi, I need some help with translation'),\n",
              " AIMessage(content='Yes please, tell me')]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parser.invoke(model.invoke(message2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ebuzh2oJjpSh",
        "outputId": "dd22fb74-7513-4729-8667-1d8be8a79181"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'नमस्ते, मुझे अनुवाद में मदद चाहिए।'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain = model|parser\n",
        "chain.invoke(message2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "G0JwKEMtj9DC",
        "outputId": "6e976bef-1dff-49e6-9007-8936992fd942"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'नमस्ते, मुझे अनुवाद में मदद चाहिए।'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example we want to create a template of System and HumanMessage hence we used respective prompt Templates"
      ],
      "metadata": {
        "id": "7vO2LfawC_bI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import SystemMessagePromptTemplate\n",
        "from langchain_core.prompts import HumanMessagePromptTemplate\n",
        "\n",
        "chat_template = ChatPromptTemplate.from_messages([\n",
        "        SystemMessagePromptTemplate.from_template(\"You are a helpful assistant that rewrites user input to sound more {tone}\"),\n",
        "        HumanMessagePromptTemplate.from_template(\"{text}\")\n",
        "\n",
        "])\n",
        "\n",
        "messages = chat_template.format_messages(tone=\"upbeat\",text=\"I don't like eating tasty things\")\n",
        "print(messages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmVwprnN-2Ww",
        "outputId": "bbb05804-7fce-45ca-a7ee-c1f3e4b9c9c3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SystemMessage(content='You are a helpful assistant that rewrites user input to sound more upbeat'), HumanMessage(content=\"I don't like eating tasty things\")]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets see the use of MessagesPlaceholder"
      ],
      "metadata": {
        "id": "gBXTClblFR0f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import(\n",
        "    ChatPromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        "    MessagesPlaceholder\n",
        ")\n",
        "\n",
        "message_template4 = ChatPromptTemplate.from_messages([\n",
        "    SystemMessagePromptTemplate.from_template(\"You are a helpful and rude assistant. You name is {name}.\"),\n",
        "    MessagesPlaceholder(variable_name=\"conversation\"),\n",
        "    HumanMessagePromptTemplate.from_template(\"Summarize our conversation so far in {word_count} words\"),\n",
        "\n",
        "\n",
        "])\n",
        "message_template4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijsFLUYfFT-B",
        "outputId": "22ab06ba-176d-4a6b-a5d8-7ff8a3cfd056"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['conversation', 'name', 'word_count'], input_types={'conversation': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['name'], template='You are a helpful and rude assistant. You name is {name}.')), MessagesPlaceholder(variable_name='conversation'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['word_count'], template='Summarize our conversation so far in {word_count} words'))])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import AIMessage, HumanMessage\n",
        "\n",
        "\n",
        "human_message = HumanMessage(content=\"What is the best way to learn programming?\")\n",
        "ai_message = AIMessage(\n",
        "    content=\"\"\"\\\n",
        "1. Choose a programming language: Decide on a programming language that you want to learn.\n",
        "\n",
        "2. Start with the basics: Familiarize yourself with the basic programming concepts such as variables, data types and control structures.\n",
        "\n",
        "3. Practice, practice, practice: The best way to learn programming is through hands-on experience\\\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "message2 = [\n",
        "\n",
        "    HumanMessage(content=\"Hi, I need some help with translation\"),\n",
        "    AIMessage(content=\"Yes please, tell me\"),\n",
        "    HumanMessage(\"I need sandwich recipe\")\n",
        "]\n",
        "message_template4.format_prompt(name=\"Andy\",\n",
        "    #conversation=[human_message, ai_message],\n",
        "    conversation=message2,\n",
        "    word_count=\"10\"\n",
        ").to_messages()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zMoajNM3Ov2",
        "outputId": "acad6c71-2f77-4bb2-bc96-1004b6a261f1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SystemMessage(content='You are a helpful and rude assistant. You name is Andy.'),\n",
              " HumanMessage(content='Hi, I need some help with translation'),\n",
              " AIMessage(content='Yes please, tell me'),\n",
              " HumanMessage(content='I need sandwich recipe'),\n",
              " HumanMessage(content='Summarize our conversation so far in 10 words')]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}