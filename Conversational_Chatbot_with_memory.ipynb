{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPo99fmRDWC17HlTSvtJq1t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/y-pred/Langchain/blob/main/Conversational_Chatbot_with_memory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain -q\n",
        "!pip install openai -q"
      ],
      "metadata": {
        "id": "Ep-aD30Qj0PS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Chatmodels"
      ],
      "metadata": {
        "id": "NvJ9i3Etuyh3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "chat = ChatOpenAI(temperature=0.3)"
      ],
      "metadata": {
        "id": "ELTg5zDgu0T0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema import HumanMessage,SystemMessage,AIMessage\n",
        "response = chat([\n",
        "SystemMessage(content=\"Yor are a AI assitant with a sense of humor\"),\n",
        "HumanMessage(content=\"I am going for an interview, can you give me some advice\")\n",
        "])"
      ],
      "metadata": {
        "id": "c78_wHkpvStI"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThdYHAhOesVm",
        "outputId": "3a6bb8b2-5a22-468a-b896-cad1ade79b64"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"Of course! Remember to dress to impress, maintain good eye contact, and don't forget to smile. And most importantly, be yourself - unless you can be a unicorn, then definitely be a unicorn. Good luck!\", response_metadata={'token_usage': {'completion_tokens': 44, 'prompt_tokens': 36, 'total_tokens': 80}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'stop', 'logprobs': None}, id='run-91d12a46-edc4-4fcc-b5f1-92edcc24f5bb-0')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Streamlit app -Simple QnA with Memory"
      ],
      "metadata": {
        "id": "xz0OxNrJjP8z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit\n",
        "!pip install pyngrok"
      ],
      "metadata": {
        "id": "Zpm3EARGh5ii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import os\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import HumanMessage,SystemMessage,AIMessage\n",
        "\n",
        "#Langchain function\n",
        "def get_chatmodel_response(question):\n",
        "    os.environ['OPENAI_API_KEY'] = 'OPEN_API_KEY'\n",
        "\n",
        "    chat=ChatOpenAI(temperature=0.5)\n",
        "    st.session_state['flowmessages'].append(HumanMessage(content=question))\n",
        "    answer=chat(st.session_state['flowmessages'])\n",
        "    st.session_state['flowmessages'].append(AIMessage(content=answer.content))\n",
        "    return answer.content\n",
        "\n",
        "\n",
        "\n",
        "## Streamlit UI\n",
        "st.set_page_config(page_title=\"Conversational Q&A Chatbot\")\n",
        "st.header(\"Hey, Let's Chat\")\n",
        "\n",
        "if 'flowmessages' not in st.session_state:\n",
        "    st.session_state['flowmessages']=[\n",
        "        SystemMessage(content=\"Yor are an AI assistant with a sense of humor\")\n",
        "    ]\n",
        "\n",
        "input=st.text_input(\"Input: \",key=\"input\")\n",
        "response=get_chatmodel_response(input)\n",
        "\n",
        "submit=st.button(\"Ask a question\")\n",
        "\n",
        "## If ask button is clicked\n",
        "\n",
        "if submit:\n",
        "    st.subheader(\"The Response is\")\n",
        "    st.write(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTNDt3OYd77o",
        "outputId": "2dd83ad4-60ae-46fb-87bf-0804c5248648"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "#Set auth token\n",
        "ngrok.set_auth_token(\"2c54S0BCzBB0ZiGw5FSS82ulUNb_7wsNuyyPb22woziTCnnXn\")\n",
        "\n",
        "!nohup streamlit run app.py --server.port 5011 &\n",
        "# Start ngrok tunnel\n",
        "ngrok_tunnel = ngrok.connect(addr='5011', proto='http', bind_tls=True)\n",
        "\n",
        "# Print the URL\n",
        "print(' * Tunnel URL:', ngrok_tunnel.public_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvRE7j_Dh3sc",
        "outputId": "1b0464e9-62ec-4014-ce8d-0fbbbdfa3019"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nohup: appending output to 'nohup.out'\n",
            " * Tunnel URL: https://af01-34-132-67-118.ngrok-free.app\n"
          ]
        }
      ]
    }
  ]
}